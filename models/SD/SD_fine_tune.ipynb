{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imemmul/GenerativeNFT/blob/main/models/SD/SD_fine_tune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf diffusers"
      ],
      "metadata": {
        "id": "zwjnl_J67prO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TLOVY8PlJBD",
        "outputId": "d7b30d7e-d762-4f78-8213-778a24c4f62a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 58930, done.\u001b[K\n",
            "remote: Counting objects: 100% (513/513), done.\u001b[K\n",
            "remote: Compressing objects: 100% (284/284), done.\u001b[K\n",
            "remote: Total 58930 (delta 308), reused 344 (delta 204), pack-reused 58417\u001b[K\n",
            "Receiving objects: 100% (58930/58930), 40.83 MiB | 13.36 MiB/s, done.\n",
            "Resolving deltas: 100% (42693/42693), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/huggingface/diffusers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmLHhwW_FVd0",
        "outputId": "8578ca63-f5e3-4ead-a673-fe1cff4be679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusers  drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NGhdDqQ4Hw2l",
        "outputId": "98aa3635-e2a7-476e-fc2e-c65deeb49250"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.1+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WY4QmIUTHNeP",
        "outputId": "c7057175-1662-4764-d3f0-03238616f35b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.25.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.2.1->xformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.1->xformers) (12.4.99)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.2.1->xformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.2.1->xformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waYxAKztE_M1",
        "outputId": "dd05a2a6-1b29-4e2e-f9ae-af81574fe250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusers\n",
            "Processing /content/diffusers\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (7.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers==0.28.0.dev0) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers==0.28.0.dev0) (24.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers==0.28.0.dev0) (3.18.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.28.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.28.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.28.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers==0.28.0.dev0) (2024.2.2)\n",
            "Building wheels for collected packages: diffusers\n",
            "  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for diffusers: filename=diffusers-0.28.0.dev0-py3-none-any.whl size=2029710 sha256=75bc6d32eea39b500467ea0b5144b8e84fc11f4d70e2eb922a020b862fde888c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fet8pr1b/wheels/95/c5/3b/e1b4269f8a2584de57e75f949a185b48fc4144e9a91fc9965a\n",
            "Successfully built diffusers\n",
            "Installing collected packages: diffusers\n",
            "  Attempting uninstall: diffusers\n",
            "    Found existing installation: diffusers 0.28.0.dev0\n",
            "    Uninstalling diffusers-0.28.0.dev0:\n",
            "      Successfully uninstalled diffusers-0.28.0.dev0\n",
            "Successfully installed diffusers-0.28.0.dev0\n"
          ]
        }
      ],
      "source": [
        "%cd ./diffusers\n",
        "!pip install ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "litNm49rFe5u",
        "outputId": "a942b3c7-4fd1-4690-8ca0-b474e826903f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/diffusers/examples/text_to_image\n"
          ]
        }
      ],
      "source": [
        "%cd ./examples/text_to_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlCFe5B1FjtR",
        "outputId": "d8556f6b-31a3-4120-885e-105c4de4ac6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate>=0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.28.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.17.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.25.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (4.38.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (2.18.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (6.2.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (2.15.2)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (3.1.3)\n",
            "Requirement already satisfied: peft==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (24.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (4.66.2)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (0.4.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.7.0->-r requirements.txt (line 8)) (0.20.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (12.4.99)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.25.1->-r requirements.txt (line 3)) (0.15.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 4)) (3.9.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->-r requirements.txt (line 5)) (0.2.13)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.62.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.6)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 6)) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2->-r requirements.txt (line 7)) (2.1.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 4)) (4.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (1.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.25.1->-r requirements.txt (line 3)) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->-r requirements.txt (line 4)) (2023.4)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 6)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.7.0->-r requirements.txt (line 8)) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61llsfq0ufSO",
        "outputId": "64541c15-7f52-4727-b2ad-e7bff6423679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r----------------------------------------------------------------------------------------------------In which compute environment are you running?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mThis machine\u001b[0m\r\n",
            "    AWS (Amazon SageMaker)\n",
            "\u001b[2A\u001b[?25l0\n",
            "\u001b[32mThis machine\u001b[0m\n",
            "----------------------------------------------------------------------------------------------------Which type of machine are you using?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mNo distributed training\u001b[0m\n",
            "    multi-CPU\n",
            "    multi-XPU\n",
            "    multi-GPU\n",
            "    multi-NPU\n",
            "    TPU\n",
            "\u001b[6A\u001b[?25l0\n",
            "\u001b[32mNo distributed training\u001b[0m\n",
            "\u001b[?25hDo you want to run your training on CPU only (even if a GPU / Apple Silicon / Ascend NPU device is available)? [yes/NO]:NO\n",
            "Do you wish to optimize your script with torch dynamo?[yes/NO]:NO\n",
            "Do you want to use DeepSpeed? [yes/NO]: NO\n",
            "What GPU(s) (by id) should be used for training on this machine as a comma-seperated list? [all]:0\n",
            "----------------------------------------------------------------------------------------------------Do you wish to use FP16 or BF16 (mixed precision)?\n",
            "Please input a choice index (starting from 0), and press enter\n",
            " ➔  \u001b[32mno\u001b[0m\n",
            "    fp16\n",
            "    bf16\n",
            "    fp8\n",
            "\u001b[4A\u001b[?25l1\n",
            "\u001b[32mfp16\u001b[0m\n",
            "\u001b[?25haccelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ],
      "source": [
        "!accelerate config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sMV9uZ6-tq1",
        "outputId": "ba498adc-210f-4e04-8998-223ab4d73bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) n\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXGi78mpGbgm",
        "outputId": "826273ad-6e82-47c1-f760-7a5e3f769232"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZOlKspUdqdg",
        "outputId": "8ae7c6ba-5e5b-435d-dc26-d506646f254f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-26 13:26:32.103546: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-26 13:26:32.103602: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-26 13:26:32.105218: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-26 13:26:33.187289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "03/26/2024 13:26:33 - INFO - __main__ - Distributed environment: NO\n",
            "Num processes: 1\n",
            "Process index: 0\n",
            "Local process index: 0\n",
            "Device: cuda\n",
            "\n",
            "Mixed precision type: fp16\n",
            "\n",
            "scheduler/scheduler_config.json: 100% 345/345 [00:00<00:00, 1.93MB/s]\n",
            "{'rescale_betas_zero_snr', 'clip_sample_range', 'thresholding', 'sample_max_value', 'timestep_spacing', 'variance_type', 'dynamic_thresholding_ratio'} was not found in config. Values will be initialized to default values.\n",
            "tokenizer/tokenizer_config.json: 100% 824/824 [00:00<00:00, 4.69MB/s]\n",
            "tokenizer/vocab.json: 100% 1.06M/1.06M [00:00<00:00, 1.08MB/s]\n",
            "tokenizer/merges.txt: 100% 525k/525k [00:00<00:00, 2.10MB/s]\n",
            "tokenizer/special_tokens_map.json: 100% 460/460 [00:00<00:00, 1.97MB/s]\n",
            "text_encoder/config.json: 100% 633/633 [00:00<00:00, 3.70MB/s]\n",
            "model.safetensors: 100% 1.36G/1.36G [00:04<00:00, 331MB/s]\n",
            "vae/config.json: 100% 611/611 [00:00<00:00, 3.16MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 335M/335M [00:01<00:00, 269MB/s]\n",
            "{'force_upcast', 'latents_std', 'latents_mean', 'scaling_factor'} was not found in config. Values will be initialized to default values.\n",
            "unet/config.json: 100% 939/939 [00:00<00:00, 5.68MB/s]\n",
            "diffusion_pytorch_model.safetensors: 100% 3.46G/3.46G [00:10<00:00, 345MB/s]\n",
            "{'mid_block_only_cross_attention', 'addition_time_embed_dim', 'encoder_hid_dim_type', 'class_embed_type', 'num_attention_heads', 'resnet_time_scale_shift', 'conv_in_kernel', 'time_embedding_type', 'addition_embed_type_num_heads', 'time_embedding_act_fn', 'time_cond_proj_dim', 'cross_attention_norm', 'dropout', 'time_embedding_dim', 'reverse_transformer_layers_per_block', 'encoder_hid_dim', 'resnet_out_scale_factor', 'addition_embed_type', 'conv_out_kernel', 'resnet_skip_time_act', 'timestep_post_act', 'transformer_layers_per_block', 'projection_class_embeddings_input_dim', 'attention_type', 'class_embeddings_concat', 'mid_block_type'} was not found in config. Values will be initialized to default values.\n",
            "Resolving data files: 100% 55347/55347 [00:00<00:00, 133648.37it/s]\n",
            "Computing checksums: 100% 55347/55347 [00:07<00:00, 7166.23it/s]\n",
            "Generating train split: 55346 examples [00:09, 6096.24 examples/s]\n",
            "03/26/2024 13:28:14 - INFO - __main__ - ***** Running training *****\n",
            "03/26/2024 13:28:14 - INFO - __main__ -   Num examples = 55346\n",
            "03/26/2024 13:28:14 - INFO - __main__ -   Num Epochs = 1\n",
            "03/26/2024 13:28:14 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
            "03/26/2024 13:28:14 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
            "03/26/2024 13:28:14 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
            "03/26/2024 13:28:14 - INFO - __main__ -   Total optimization steps = 30000\n",
            "Steps:   0% 147/30000 [03:26<10:16:08,  1.24s/it, lr=1e-5, step_loss=0.265]/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "Steps:   2% 500/30000 [11:16<10:05:04,  1.23s/it, lr=1e-5, step_loss=0.641]03/26/2024 13:39:30 - INFO - accelerate.accelerator - Saving current state to /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500\n",
            "Configuration saved in /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500/unet/config.json\n",
            "Model weights saved in /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500/unet/diffusion_pytorch_model.safetensors\n",
            "03/26/2024 13:40:02 - INFO - accelerate.checkpointing - Optimizer state saved in /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500/optimizer.bin\n",
            "03/26/2024 13:40:02 - INFO - accelerate.checkpointing - Scheduler state saved in /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500/scheduler.bin\n",
            "03/26/2024 13:40:02 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500/sampler.bin\n",
            "03/26/2024 13:40:02 - INFO - accelerate.checkpointing - Gradient scaler state saved in /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500/scaler.pt\n",
            "03/26/2024 13:40:05 - INFO - accelerate.checkpointing - Random states saved in /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500/random_states_0.pkl\n",
            "03/26/2024 13:40:05 - INFO - __main__ - Saved state to /content/drive/MyDrive/output_50k_SD_w0_LoRa/checkpoint-500\n",
            "Steps:   2% 577/30000 [13:37<10:06:32,  1.24s/it, lr=1e-5, step_loss=0.365]"
          ]
        }
      ],
      "source": [
        "MODEL_NAME=\"stabilityai/stable-diffusion-2-1\"\n",
        "OUTPUT_DIR=\"/content/drive/MyDrive/output_50k_SD_w0_LoRa\"\n",
        "train_data=\"/content/drive/MyDrive/output_captioning/NFT_DATASET_MERGED/train\"\n",
        "!accelerate launch /content/diffusers/examples/text_to_image/train_text_to_image.py \\\n",
        "  --pretrained_model_name_or_path=$MODEL_NAME \\\n",
        "  --train_data_dir=$train_data \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --resolution=512 --center_crop --random_flip \\\n",
        "  --train_batch_size=1 \\\n",
        "  --max_train_steps=30000 \\\n",
        "  --learning_rate=1e-05 \\\n",
        "  --max_grad_norm=1 \\\n",
        "  --output_dir=$OUTPUT_DIR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "train_directory = '/content/drive/MyDrive/output_captioning/NFT_DATASET_MERGED/train'\n",
        "\n",
        "os.chdir(train_directory)\n",
        "\n",
        "collections = [d for d in os.listdir() if os.path.isdir(d) and d != '.ipynb_checkpoints']\n",
        "\n",
        "\n",
        "for collection in collections:\n",
        "    collection_path = os.path.join(train_directory, collection)\n",
        "    os.chdir(collection_path)\n",
        "\n",
        "    file_to_check = \"Okay Bear #1051_augmented_0.png\"\n",
        "    file_path = os.path.join(collection_path, file_to_check)\n",
        "\n",
        "    if os.path.exists(file_path):\n",
        "        print(f\"File '{file_to_check}' found in collection '{collection}'\")\n",
        "    else:\n",
        "        print(f\"File '{file_to_check}' not found in collection '{collection}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVaLgVX53tUO",
        "outputId": "75a9d8cd-12a9-429e-fb1d-7a152958a2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File 'Okay Bear #1051_augmented_0.png' not found in collection 'degenfatcats'\n",
            "File 'Okay Bear #1051_augmented_0.png' not found in collection 'Okay Bears'\n",
            "File 'Okay Bear #1051_augmented_0.png' not found in collection 'shadowy_super_coder_dao'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o4Qm5Pqyf6ck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c933112-7a68-47d7-aac5-744d3bf7a641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Count of augmented file name : 0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "metadata_df = pd.read_csv('/content/drive/MyDrive/output_captioning/NFT_DATASET_MERGED/train/metadata.csv')\n",
        "\n",
        "count = 0\n",
        "for index, row in metadata_df.iterrows():\n",
        "    file_name = row['file_name']\n",
        "    if 'augmented' in file_name:\n",
        "        print(file_name)\n",
        "        count += 1\n",
        "\n",
        "print(f\"Count of augmented file name : {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/output_captioning/NFT_DATASET_MERGED/train'\n",
        "metadata_csv_path = '/content/drive/MyDrive/output_captioning/NFT_DATASET_MERGED/train/metadata.csv'\n",
        "df = pd.read_csv(metadata_csv_path)\n",
        "image_names = df['file_name'].tolist()\n",
        "print(len(image_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEN9i_Leufd2",
        "outputId": "3d60546b-505a-42b2-d9f5-9680933d9cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.chdir(train_dir)\n",
        "collections = [d for d in os.listdir() if os.path.isdir(d) and d != '.ipynb_checkpoints']\n",
        "#print(collections)\n",
        "\n",
        "total_augmented_removed = 0\n",
        "for collection in collections:\n",
        "    collection_path = os.path.join(train_dir, collection)\n",
        "    #print(collection_path)\n",
        "    os.chdir(collection_path)\n",
        "    files = os.listdir()\n",
        "    #print(f\"Files in collection '{collection}': {files}\")\n",
        "    augmented_files = [file for file in files if 'augmented' in file]\n",
        "    num_augmented_files = len(augmented_files)\n",
        "    #print(f\"Len of augmented files: {num_augmented_files}\")\n",
        "    if num_augmented_files > 0:\n",
        "        total_augmented_removed += num_augmented_files\n",
        "        for file in augmented_files:\n",
        "            try:\n",
        "                os.remove(file)\n",
        "                print(f\"Deleted: {file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error deleting {file}: {str(e)}\")\n",
        "    else:\n",
        "        print(f\"No files containing 'augmented' found in collection '{collection}'\")\n",
        "\n",
        "print(f\"Total augmented files removed: {total_augmented_removed}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmPFv23su7qb",
        "outputId": "44ee76e4-b097-4eff-9792-3049c8b57fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No files containing 'augmented' found in collection 'degenfatcats'\n",
            "No files containing 'augmented' found in collection 'Okay Bears'\n",
            "No files containing 'augmented' found in collection 'shadowy_super_coder_dao'\n",
            "No files containing 'augmented' found in collection 'new_collection'\n",
            "No files containing 'augmented' found in collection 'Degods'\n",
            "No files containing 'augmented' found in collection 'degenerate_ape_academy'\n",
            "No files containing 'augmented' found in collection 'y00ts'\n",
            "No files containing 'augmented' found in collection 'cets_on_creck'\n",
            "No files containing 'augmented' found in collection 'famous_fox_federation'\n",
            "No files containing 'augmented' found in collection 'blocksmith_labs'\n",
            "No files containing 'augmented' found in collection 'the_remnants_'\n",
            "No files containing 'augmented' found in collection 'solana_monkey_business'\n",
            "Total augmented files removed: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "17060+3160+3000+3000+3000+3020+2940+3000+3000+3020+3000+3020"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6mB0_OXyEz6",
        "outputId": "b46750b0-994f-4a0c-f80c-ee41ca1b65af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50220"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for collection in collections:\n",
        "    collection_path = os.path.join(train_dir, collection)\n",
        "    os.chdir(collection_path)\n",
        "\n",
        "    files = os.listdir()\n",
        "    augmented_files = [file for file in files if 'augmented' in file]\n",
        "    num_augmented_files = len(augmented_files)\n",
        "    print(num_augmented_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuIdeNPnzow6",
        "outputId": "14c97b2c-f627-4d14-bb4a-4b290d6f6ab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "metadata_df = pd.read_csv('./metadata.csv')\n",
        "print(metadata_df.head())\n",
        "print(metadata_df['file_name'].head())"
      ],
      "metadata": {
        "id": "49ejWMZFy_mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "column_name = 'file_name'\n",
        "augmented_count = metadata_df[column_name].str.contains('augmented', case=False).sum()\n",
        "print(\"Number of occurrences of 'augmented' in column '{}': {}\".format(column_name, augmented_count))"
      ],
      "metadata": {
        "id": "qjKnWjnPzFkI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = ['Unnamed: 0.1','Unnamed: 0']\n",
        "metadata_df.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
        "print(metadata_df.columns)"
      ],
      "metadata": {
        "id": "gGr4qW1ozJ9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for index, row in metadata_df.iterrows():\n",
        "    file_name = row['file_name']\n",
        "    if 'augmented' in file_name:\n",
        "        print(file_name)\n",
        "        count += 1\n",
        "\n",
        "print(f\"Count of augmented file name : {count}\")"
      ],
      "metadata": {
        "id": "B2doRHQ2zLnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(metadata_df)-50220)"
      ],
      "metadata": {
        "id": "q_jvOoNbzNoI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "original_df = metadata_df[~metadata_df['file_name'].str.contains('augmented', case=False)]\n",
        "original_df_path = './metadata_wt_augmented.csv'\n",
        "original_df.to_csv(original_df_path, index=False)"
      ],
      "metadata": {
        "id": "ByLuNCftzO_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "not_augmented_df = pd.read_csv('/Users/beyzakaya/Desktop/bk/Akademik/Senior Design Project/GenerativeNFT/metadata_wt_augmented.csv')\n",
        "print(len(not_augmented_df))"
      ],
      "metadata": {
        "id": "v-viBiQ6zQuV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}